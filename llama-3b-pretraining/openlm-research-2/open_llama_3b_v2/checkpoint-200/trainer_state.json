{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.7876923076923077,
  "eval_steps": 500,
  "global_step": 200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.003938461538461538,
      "grad_norm": 3.5,
      "learning_rate": 2.9960474308300397e-05,
      "loss": 0.6708,
      "step": 1
    },
    {
      "epoch": 0.007876923076923076,
      "grad_norm": 2.59375,
      "learning_rate": 2.992094861660079e-05,
      "loss": 0.4419,
      "step": 2
    },
    {
      "epoch": 0.011815384615384615,
      "grad_norm": 2.203125,
      "learning_rate": 2.9881422924901186e-05,
      "loss": 0.516,
      "step": 3
    },
    {
      "epoch": 0.015753846153846153,
      "grad_norm": 3.28125,
      "learning_rate": 2.9841897233201582e-05,
      "loss": 0.5013,
      "step": 4
    },
    {
      "epoch": 0.019692307692307693,
      "grad_norm": 14.625,
      "learning_rate": 2.9802371541501978e-05,
      "loss": 0.6127,
      "step": 5
    },
    {
      "epoch": 0.02363076923076923,
      "grad_norm": 5.6875,
      "learning_rate": 2.9762845849802374e-05,
      "loss": 0.4964,
      "step": 6
    },
    {
      "epoch": 0.02756923076923077,
      "grad_norm": 9.75,
      "learning_rate": 2.9723320158102767e-05,
      "loss": 0.7296,
      "step": 7
    },
    {
      "epoch": 0.031507692307692306,
      "grad_norm": 3.484375,
      "learning_rate": 2.9683794466403163e-05,
      "loss": 0.4137,
      "step": 8
    },
    {
      "epoch": 0.03544615384615385,
      "grad_norm": 3.765625,
      "learning_rate": 2.9644268774703556e-05,
      "loss": 0.2209,
      "step": 9
    },
    {
      "epoch": 0.039384615384615386,
      "grad_norm": 1.03125,
      "learning_rate": 2.9604743083003952e-05,
      "loss": 0.1697,
      "step": 10
    },
    {
      "epoch": 0.04332307692307692,
      "grad_norm": 3.0625,
      "learning_rate": 2.956521739130435e-05,
      "loss": 0.2274,
      "step": 11
    },
    {
      "epoch": 0.04726153846153846,
      "grad_norm": 4.21875,
      "learning_rate": 2.9525691699604745e-05,
      "loss": 0.1805,
      "step": 12
    },
    {
      "epoch": 0.0512,
      "grad_norm": 1.2421875,
      "learning_rate": 2.948616600790514e-05,
      "loss": 0.1904,
      "step": 13
    },
    {
      "epoch": 0.05513846153846154,
      "grad_norm": 3.6875,
      "learning_rate": 2.9446640316205534e-05,
      "loss": 0.2973,
      "step": 14
    },
    {
      "epoch": 0.059076923076923075,
      "grad_norm": 8.9375,
      "learning_rate": 2.940711462450593e-05,
      "loss": 0.1088,
      "step": 15
    },
    {
      "epoch": 0.06301538461538461,
      "grad_norm": 1.140625,
      "learning_rate": 2.9367588932806326e-05,
      "loss": 0.132,
      "step": 16
    },
    {
      "epoch": 0.06695384615384616,
      "grad_norm": 0.8671875,
      "learning_rate": 2.932806324110672e-05,
      "loss": 0.0775,
      "step": 17
    },
    {
      "epoch": 0.0708923076923077,
      "grad_norm": 1.2265625,
      "learning_rate": 2.9288537549407115e-05,
      "loss": 0.0949,
      "step": 18
    },
    {
      "epoch": 0.07483076923076923,
      "grad_norm": 0.9765625,
      "learning_rate": 2.9249011857707508e-05,
      "loss": 0.0961,
      "step": 19
    },
    {
      "epoch": 0.07876923076923077,
      "grad_norm": 1.65625,
      "learning_rate": 2.9209486166007908e-05,
      "loss": 0.072,
      "step": 20
    },
    {
      "epoch": 0.0827076923076923,
      "grad_norm": 0.52734375,
      "learning_rate": 2.9169960474308304e-05,
      "loss": 0.0846,
      "step": 21
    },
    {
      "epoch": 0.08664615384615384,
      "grad_norm": 3.6875,
      "learning_rate": 2.9130434782608696e-05,
      "loss": 0.1299,
      "step": 22
    },
    {
      "epoch": 0.09058461538461539,
      "grad_norm": 1.640625,
      "learning_rate": 2.9090909090909093e-05,
      "loss": 0.0723,
      "step": 23
    },
    {
      "epoch": 0.09452307692307692,
      "grad_norm": 1.75,
      "learning_rate": 2.9051383399209485e-05,
      "loss": 0.0505,
      "step": 24
    },
    {
      "epoch": 0.09846153846153846,
      "grad_norm": 0.69140625,
      "learning_rate": 2.901185770750988e-05,
      "loss": 0.0487,
      "step": 25
    },
    {
      "epoch": 0.1024,
      "grad_norm": 0.83984375,
      "learning_rate": 2.8972332015810278e-05,
      "loss": 0.043,
      "step": 26
    },
    {
      "epoch": 0.10633846153846153,
      "grad_norm": 0.431640625,
      "learning_rate": 2.893280632411067e-05,
      "loss": 0.0411,
      "step": 27
    },
    {
      "epoch": 0.11027692307692308,
      "grad_norm": 0.7734375,
      "learning_rate": 2.889328063241107e-05,
      "loss": 0.08,
      "step": 28
    },
    {
      "epoch": 0.11421538461538462,
      "grad_norm": 0.61328125,
      "learning_rate": 2.8853754940711463e-05,
      "loss": 0.059,
      "step": 29
    },
    {
      "epoch": 0.11815384615384615,
      "grad_norm": 1.7421875,
      "learning_rate": 2.881422924901186e-05,
      "loss": 0.0291,
      "step": 30
    },
    {
      "epoch": 0.1220923076923077,
      "grad_norm": 0.48828125,
      "learning_rate": 2.8774703557312255e-05,
      "loss": 0.0389,
      "step": 31
    },
    {
      "epoch": 0.12603076923076922,
      "grad_norm": 0.84765625,
      "learning_rate": 2.8735177865612648e-05,
      "loss": 0.0644,
      "step": 32
    },
    {
      "epoch": 0.12996923076923078,
      "grad_norm": 0.55078125,
      "learning_rate": 2.8695652173913044e-05,
      "loss": 0.0341,
      "step": 33
    },
    {
      "epoch": 0.1339076923076923,
      "grad_norm": 0.2578125,
      "learning_rate": 2.8656126482213437e-05,
      "loss": 0.0123,
      "step": 34
    },
    {
      "epoch": 0.13784615384615384,
      "grad_norm": 0.3046875,
      "learning_rate": 2.8616600790513833e-05,
      "loss": 0.0259,
      "step": 35
    },
    {
      "epoch": 0.1417846153846154,
      "grad_norm": 0.578125,
      "learning_rate": 2.8577075098814233e-05,
      "loss": 0.0221,
      "step": 36
    },
    {
      "epoch": 0.14572307692307693,
      "grad_norm": 0.337890625,
      "learning_rate": 2.8537549407114626e-05,
      "loss": 0.0409,
      "step": 37
    },
    {
      "epoch": 0.14966153846153846,
      "grad_norm": 0.6328125,
      "learning_rate": 2.8498023715415022e-05,
      "loss": 0.0386,
      "step": 38
    },
    {
      "epoch": 0.1536,
      "grad_norm": 0.294921875,
      "learning_rate": 2.8458498023715415e-05,
      "loss": 0.0159,
      "step": 39
    },
    {
      "epoch": 0.15753846153846154,
      "grad_norm": 0.375,
      "learning_rate": 2.841897233201581e-05,
      "loss": 0.0322,
      "step": 40
    },
    {
      "epoch": 0.16147692307692307,
      "grad_norm": 0.2490234375,
      "learning_rate": 2.8379446640316207e-05,
      "loss": 0.0316,
      "step": 41
    },
    {
      "epoch": 0.1654153846153846,
      "grad_norm": 0.1728515625,
      "learning_rate": 2.83399209486166e-05,
      "loss": 0.0137,
      "step": 42
    },
    {
      "epoch": 0.16935384615384616,
      "grad_norm": 0.2890625,
      "learning_rate": 2.8300395256916996e-05,
      "loss": 0.0295,
      "step": 43
    },
    {
      "epoch": 0.1732923076923077,
      "grad_norm": 0.271484375,
      "learning_rate": 2.8260869565217392e-05,
      "loss": 0.0154,
      "step": 44
    },
    {
      "epoch": 0.17723076923076922,
      "grad_norm": 0.1845703125,
      "learning_rate": 2.822134387351779e-05,
      "loss": 0.0324,
      "step": 45
    },
    {
      "epoch": 0.18116923076923078,
      "grad_norm": 0.263671875,
      "learning_rate": 2.8181818181818185e-05,
      "loss": 0.0184,
      "step": 46
    },
    {
      "epoch": 0.1851076923076923,
      "grad_norm": 0.291015625,
      "learning_rate": 2.8142292490118577e-05,
      "loss": 0.0238,
      "step": 47
    },
    {
      "epoch": 0.18904615384615384,
      "grad_norm": 0.23046875,
      "learning_rate": 2.8102766798418974e-05,
      "loss": 0.02,
      "step": 48
    },
    {
      "epoch": 0.1929846153846154,
      "grad_norm": 0.1259765625,
      "learning_rate": 2.8063241106719366e-05,
      "loss": 0.0116,
      "step": 49
    },
    {
      "epoch": 0.19692307692307692,
      "grad_norm": 0.271484375,
      "learning_rate": 2.8023715415019763e-05,
      "loss": 0.0208,
      "step": 50
    },
    {
      "epoch": 0.20086153846153845,
      "grad_norm": 0.1865234375,
      "learning_rate": 2.7984189723320162e-05,
      "loss": 0.0116,
      "step": 51
    },
    {
      "epoch": 0.2048,
      "grad_norm": 0.349609375,
      "learning_rate": 2.7944664031620555e-05,
      "loss": 0.0121,
      "step": 52
    },
    {
      "epoch": 0.20873846153846154,
      "grad_norm": 0.2265625,
      "learning_rate": 2.790513833992095e-05,
      "loss": 0.0305,
      "step": 53
    },
    {
      "epoch": 0.21267692307692307,
      "grad_norm": 0.2177734375,
      "learning_rate": 2.7865612648221344e-05,
      "loss": 0.0322,
      "step": 54
    },
    {
      "epoch": 0.21661538461538463,
      "grad_norm": 0.306640625,
      "learning_rate": 2.782608695652174e-05,
      "loss": 0.023,
      "step": 55
    },
    {
      "epoch": 0.22055384615384616,
      "grad_norm": 0.1728515625,
      "learning_rate": 2.7786561264822133e-05,
      "loss": 0.0199,
      "step": 56
    },
    {
      "epoch": 0.22449230769230769,
      "grad_norm": 0.298828125,
      "learning_rate": 2.774703557312253e-05,
      "loss": 0.0178,
      "step": 57
    },
    {
      "epoch": 0.22843076923076924,
      "grad_norm": 0.17578125,
      "learning_rate": 2.7707509881422925e-05,
      "loss": 0.0194,
      "step": 58
    },
    {
      "epoch": 0.23236923076923077,
      "grad_norm": 0.31640625,
      "learning_rate": 2.766798418972332e-05,
      "loss": 0.0336,
      "step": 59
    },
    {
      "epoch": 0.2363076923076923,
      "grad_norm": 0.091796875,
      "learning_rate": 2.7628458498023718e-05,
      "loss": 0.0034,
      "step": 60
    },
    {
      "epoch": 0.24024615384615386,
      "grad_norm": 0.26953125,
      "learning_rate": 2.758893280632411e-05,
      "loss": 0.0405,
      "step": 61
    },
    {
      "epoch": 0.2441846153846154,
      "grad_norm": 0.421875,
      "learning_rate": 2.7549407114624507e-05,
      "loss": 0.0156,
      "step": 62
    },
    {
      "epoch": 0.24812307692307692,
      "grad_norm": 0.197265625,
      "learning_rate": 2.7509881422924903e-05,
      "loss": 0.0139,
      "step": 63
    },
    {
      "epoch": 0.25206153846153845,
      "grad_norm": 0.1025390625,
      "learning_rate": 2.7470355731225296e-05,
      "loss": 0.0069,
      "step": 64
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.470703125,
      "learning_rate": 2.7430830039525692e-05,
      "loss": 0.016,
      "step": 65
    },
    {
      "epoch": 0.25993846153846156,
      "grad_norm": 0.2177734375,
      "learning_rate": 2.7391304347826085e-05,
      "loss": 0.0054,
      "step": 66
    },
    {
      "epoch": 0.26387692307692306,
      "grad_norm": 0.2001953125,
      "learning_rate": 2.7351778656126484e-05,
      "loss": 0.0297,
      "step": 67
    },
    {
      "epoch": 0.2678153846153846,
      "grad_norm": 0.359375,
      "learning_rate": 2.731225296442688e-05,
      "loss": 0.0266,
      "step": 68
    },
    {
      "epoch": 0.2717538461538462,
      "grad_norm": 0.140625,
      "learning_rate": 2.7272727272727273e-05,
      "loss": 0.01,
      "step": 69
    },
    {
      "epoch": 0.2756923076923077,
      "grad_norm": 0.1455078125,
      "learning_rate": 2.723320158102767e-05,
      "loss": 0.0117,
      "step": 70
    },
    {
      "epoch": 0.27963076923076924,
      "grad_norm": 0.2314453125,
      "learning_rate": 2.7193675889328062e-05,
      "loss": 0.019,
      "step": 71
    },
    {
      "epoch": 0.2835692307692308,
      "grad_norm": 0.140625,
      "learning_rate": 2.7154150197628458e-05,
      "loss": 0.02,
      "step": 72
    },
    {
      "epoch": 0.2875076923076923,
      "grad_norm": 0.1591796875,
      "learning_rate": 2.7114624505928854e-05,
      "loss": 0.0121,
      "step": 73
    },
    {
      "epoch": 0.29144615384615385,
      "grad_norm": 0.1201171875,
      "learning_rate": 2.7075098814229247e-05,
      "loss": 0.0063,
      "step": 74
    },
    {
      "epoch": 0.2953846153846154,
      "grad_norm": 0.2216796875,
      "learning_rate": 2.7035573122529647e-05,
      "loss": 0.0262,
      "step": 75
    },
    {
      "epoch": 0.2993230769230769,
      "grad_norm": 0.30859375,
      "learning_rate": 2.699604743083004e-05,
      "loss": 0.0099,
      "step": 76
    },
    {
      "epoch": 0.30326153846153847,
      "grad_norm": 0.049072265625,
      "learning_rate": 2.6956521739130436e-05,
      "loss": 0.0018,
      "step": 77
    },
    {
      "epoch": 0.3072,
      "grad_norm": 0.263671875,
      "learning_rate": 2.6916996047430832e-05,
      "loss": 0.0259,
      "step": 78
    },
    {
      "epoch": 0.31113846153846153,
      "grad_norm": 0.234375,
      "learning_rate": 2.6877470355731225e-05,
      "loss": 0.0168,
      "step": 79
    },
    {
      "epoch": 0.3150769230769231,
      "grad_norm": 0.1298828125,
      "learning_rate": 2.683794466403162e-05,
      "loss": 0.0059,
      "step": 80
    },
    {
      "epoch": 0.3190153846153846,
      "grad_norm": 0.32421875,
      "learning_rate": 2.6798418972332014e-05,
      "loss": 0.0208,
      "step": 81
    },
    {
      "epoch": 0.32295384615384615,
      "grad_norm": 0.18359375,
      "learning_rate": 2.675889328063241e-05,
      "loss": 0.0088,
      "step": 82
    },
    {
      "epoch": 0.3268923076923077,
      "grad_norm": 0.142578125,
      "learning_rate": 2.671936758893281e-05,
      "loss": 0.0058,
      "step": 83
    },
    {
      "epoch": 0.3308307692307692,
      "grad_norm": 0.1533203125,
      "learning_rate": 2.6679841897233202e-05,
      "loss": 0.0121,
      "step": 84
    },
    {
      "epoch": 0.33476923076923076,
      "grad_norm": 0.03173828125,
      "learning_rate": 2.66403162055336e-05,
      "loss": 0.0007,
      "step": 85
    },
    {
      "epoch": 0.3387076923076923,
      "grad_norm": 0.095703125,
      "learning_rate": 2.660079051383399e-05,
      "loss": 0.0033,
      "step": 86
    },
    {
      "epoch": 0.3426461538461538,
      "grad_norm": 0.1259765625,
      "learning_rate": 2.6561264822134387e-05,
      "loss": 0.0027,
      "step": 87
    },
    {
      "epoch": 0.3465846153846154,
      "grad_norm": 0.09228515625,
      "learning_rate": 2.6521739130434784e-05,
      "loss": 0.0041,
      "step": 88
    },
    {
      "epoch": 0.35052307692307694,
      "grad_norm": 0.162109375,
      "learning_rate": 2.6482213438735176e-05,
      "loss": 0.011,
      "step": 89
    },
    {
      "epoch": 0.35446153846153844,
      "grad_norm": 0.142578125,
      "learning_rate": 2.6442687747035573e-05,
      "loss": 0.0076,
      "step": 90
    },
    {
      "epoch": 0.3584,
      "grad_norm": 0.1533203125,
      "learning_rate": 2.640316205533597e-05,
      "loss": 0.0051,
      "step": 91
    },
    {
      "epoch": 0.36233846153846155,
      "grad_norm": 0.076171875,
      "learning_rate": 2.6363636363636365e-05,
      "loss": 0.0026,
      "step": 92
    },
    {
      "epoch": 0.36627692307692306,
      "grad_norm": 0.1396484375,
      "learning_rate": 2.632411067193676e-05,
      "loss": 0.0158,
      "step": 93
    },
    {
      "epoch": 0.3702153846153846,
      "grad_norm": 0.03466796875,
      "learning_rate": 2.6284584980237154e-05,
      "loss": 0.0007,
      "step": 94
    },
    {
      "epoch": 0.37415384615384617,
      "grad_norm": 0.341796875,
      "learning_rate": 2.624505928853755e-05,
      "loss": 0.0091,
      "step": 95
    },
    {
      "epoch": 0.37809230769230767,
      "grad_norm": 0.11328125,
      "learning_rate": 2.6205533596837943e-05,
      "loss": 0.0033,
      "step": 96
    },
    {
      "epoch": 0.38203076923076923,
      "grad_norm": 0.1083984375,
      "learning_rate": 2.616600790513834e-05,
      "loss": 0.0057,
      "step": 97
    },
    {
      "epoch": 0.3859692307692308,
      "grad_norm": 0.0400390625,
      "learning_rate": 2.612648221343874e-05,
      "loss": 0.0008,
      "step": 98
    },
    {
      "epoch": 0.3899076923076923,
      "grad_norm": 0.056640625,
      "learning_rate": 2.608695652173913e-05,
      "loss": 0.0009,
      "step": 99
    },
    {
      "epoch": 0.39384615384615385,
      "grad_norm": 0.115234375,
      "learning_rate": 2.6047430830039528e-05,
      "loss": 0.0014,
      "step": 100
    },
    {
      "epoch": 0.3977846153846154,
      "grad_norm": 0.076171875,
      "learning_rate": 2.600790513833992e-05,
      "loss": 0.0016,
      "step": 101
    },
    {
      "epoch": 0.4017230769230769,
      "grad_norm": 0.22265625,
      "learning_rate": 2.5968379446640317e-05,
      "loss": 0.0038,
      "step": 102
    },
    {
      "epoch": 0.40566153846153846,
      "grad_norm": 0.07373046875,
      "learning_rate": 2.5928853754940713e-05,
      "loss": 0.0011,
      "step": 103
    },
    {
      "epoch": 0.4096,
      "grad_norm": 0.048828125,
      "learning_rate": 2.5889328063241106e-05,
      "loss": 0.0006,
      "step": 104
    },
    {
      "epoch": 0.4135384615384615,
      "grad_norm": 0.10107421875,
      "learning_rate": 2.5849802371541502e-05,
      "loss": 0.002,
      "step": 105
    },
    {
      "epoch": 0.4174769230769231,
      "grad_norm": 0.2294921875,
      "learning_rate": 2.5810276679841898e-05,
      "loss": 0.0027,
      "step": 106
    },
    {
      "epoch": 0.42141538461538464,
      "grad_norm": 1.7109375,
      "learning_rate": 2.5770750988142294e-05,
      "loss": 0.0036,
      "step": 107
    },
    {
      "epoch": 0.42535384615384614,
      "grad_norm": 0.0263671875,
      "learning_rate": 2.573122529644269e-05,
      "loss": 0.0003,
      "step": 108
    },
    {
      "epoch": 0.4292923076923077,
      "grad_norm": 0.10205078125,
      "learning_rate": 2.5691699604743083e-05,
      "loss": 0.002,
      "step": 109
    },
    {
      "epoch": 0.43323076923076925,
      "grad_norm": 0.06396484375,
      "learning_rate": 2.565217391304348e-05,
      "loss": 0.0014,
      "step": 110
    },
    {
      "epoch": 0.43716923076923075,
      "grad_norm": 0.109375,
      "learning_rate": 2.5612648221343872e-05,
      "loss": 0.002,
      "step": 111
    },
    {
      "epoch": 0.4411076923076923,
      "grad_norm": 0.037353515625,
      "learning_rate": 2.557312252964427e-05,
      "loss": 0.0005,
      "step": 112
    },
    {
      "epoch": 0.44504615384615387,
      "grad_norm": 0.2431640625,
      "learning_rate": 2.5533596837944665e-05,
      "loss": 0.008,
      "step": 113
    },
    {
      "epoch": 0.44898461538461537,
      "grad_norm": 0.08740234375,
      "learning_rate": 2.549407114624506e-05,
      "loss": 0.0008,
      "step": 114
    },
    {
      "epoch": 0.45292307692307693,
      "grad_norm": 0.12158203125,
      "learning_rate": 2.5454545454545457e-05,
      "loss": 0.0022,
      "step": 115
    },
    {
      "epoch": 0.4568615384615385,
      "grad_norm": 0.10546875,
      "learning_rate": 2.541501976284585e-05,
      "loss": 0.0014,
      "step": 116
    },
    {
      "epoch": 0.4608,
      "grad_norm": 0.04443359375,
      "learning_rate": 2.5375494071146246e-05,
      "loss": 0.0005,
      "step": 117
    },
    {
      "epoch": 0.46473846153846154,
      "grad_norm": 0.0286865234375,
      "learning_rate": 2.5335968379446642e-05,
      "loss": 0.0005,
      "step": 118
    },
    {
      "epoch": 0.4686769230769231,
      "grad_norm": 0.0390625,
      "learning_rate": 2.5296442687747035e-05,
      "loss": 0.0008,
      "step": 119
    },
    {
      "epoch": 0.4726153846153846,
      "grad_norm": 0.119140625,
      "learning_rate": 2.525691699604743e-05,
      "loss": 0.0021,
      "step": 120
    },
    {
      "epoch": 0.47655384615384616,
      "grad_norm": 0.0079345703125,
      "learning_rate": 2.5217391304347824e-05,
      "loss": 0.0002,
      "step": 121
    },
    {
      "epoch": 0.4804923076923077,
      "grad_norm": 0.031005859375,
      "learning_rate": 2.5177865612648223e-05,
      "loss": 0.0007,
      "step": 122
    },
    {
      "epoch": 0.4844307692307692,
      "grad_norm": 0.04736328125,
      "learning_rate": 2.513833992094862e-05,
      "loss": 0.0008,
      "step": 123
    },
    {
      "epoch": 0.4883692307692308,
      "grad_norm": 0.2158203125,
      "learning_rate": 2.5098814229249012e-05,
      "loss": 0.0018,
      "step": 124
    },
    {
      "epoch": 0.49230769230769234,
      "grad_norm": 0.0272216796875,
      "learning_rate": 2.505928853754941e-05,
      "loss": 0.0005,
      "step": 125
    },
    {
      "epoch": 0.49624615384615384,
      "grad_norm": 0.09765625,
      "learning_rate": 2.50197628458498e-05,
      "loss": 0.0012,
      "step": 126
    },
    {
      "epoch": 0.5001846153846153,
      "grad_norm": 0.07861328125,
      "learning_rate": 2.4980237154150198e-05,
      "loss": 0.0012,
      "step": 127
    },
    {
      "epoch": 0.5041230769230769,
      "grad_norm": 0.03076171875,
      "learning_rate": 2.4940711462450594e-05,
      "loss": 0.0003,
      "step": 128
    },
    {
      "epoch": 0.5080615384615385,
      "grad_norm": 0.0966796875,
      "learning_rate": 2.4901185770750987e-05,
      "loss": 0.001,
      "step": 129
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.0498046875,
      "learning_rate": 2.4861660079051386e-05,
      "loss": 0.001,
      "step": 130
    },
    {
      "epoch": 0.5159384615384616,
      "grad_norm": 0.045166015625,
      "learning_rate": 2.482213438735178e-05,
      "loss": 0.0005,
      "step": 131
    },
    {
      "epoch": 0.5198769230769231,
      "grad_norm": 0.032958984375,
      "learning_rate": 2.4782608695652175e-05,
      "loss": 0.0006,
      "step": 132
    },
    {
      "epoch": 0.5238153846153846,
      "grad_norm": 0.042724609375,
      "learning_rate": 2.474308300395257e-05,
      "loss": 0.0008,
      "step": 133
    },
    {
      "epoch": 0.5277538461538461,
      "grad_norm": 0.1201171875,
      "learning_rate": 2.4703557312252964e-05,
      "loss": 0.0017,
      "step": 134
    },
    {
      "epoch": 0.5316923076923077,
      "grad_norm": 0.0216064453125,
      "learning_rate": 2.466403162055336e-05,
      "loss": 0.0004,
      "step": 135
    },
    {
      "epoch": 0.5356307692307692,
      "grad_norm": 0.22265625,
      "learning_rate": 2.4624505928853753e-05,
      "loss": 0.0024,
      "step": 136
    },
    {
      "epoch": 0.5395692307692308,
      "grad_norm": 0.0252685546875,
      "learning_rate": 2.4584980237154153e-05,
      "loss": 0.0004,
      "step": 137
    },
    {
      "epoch": 0.5435076923076924,
      "grad_norm": 0.06689453125,
      "learning_rate": 2.454545454545455e-05,
      "loss": 0.0008,
      "step": 138
    },
    {
      "epoch": 0.5474461538461538,
      "grad_norm": 0.037841796875,
      "learning_rate": 2.450592885375494e-05,
      "loss": 0.0004,
      "step": 139
    },
    {
      "epoch": 0.5513846153846154,
      "grad_norm": 0.1806640625,
      "learning_rate": 2.4466403162055338e-05,
      "loss": 0.0019,
      "step": 140
    },
    {
      "epoch": 0.5553230769230769,
      "grad_norm": 0.08935546875,
      "learning_rate": 2.442687747035573e-05,
      "loss": 0.001,
      "step": 141
    },
    {
      "epoch": 0.5592615384615385,
      "grad_norm": 0.05322265625,
      "learning_rate": 2.4387351778656127e-05,
      "loss": 0.0008,
      "step": 142
    },
    {
      "epoch": 0.5632,
      "grad_norm": 0.04736328125,
      "learning_rate": 2.4347826086956523e-05,
      "loss": 0.0006,
      "step": 143
    },
    {
      "epoch": 0.5671384615384616,
      "grad_norm": 0.010986328125,
      "learning_rate": 2.4308300395256916e-05,
      "loss": 0.0002,
      "step": 144
    },
    {
      "epoch": 0.571076923076923,
      "grad_norm": 0.01397705078125,
      "learning_rate": 2.4268774703557315e-05,
      "loss": 0.0002,
      "step": 145
    },
    {
      "epoch": 0.5750153846153846,
      "grad_norm": 0.021728515625,
      "learning_rate": 2.4229249011857708e-05,
      "loss": 0.0003,
      "step": 146
    },
    {
      "epoch": 0.5789538461538462,
      "grad_norm": 0.275390625,
      "learning_rate": 2.4189723320158104e-05,
      "loss": 0.0016,
      "step": 147
    },
    {
      "epoch": 0.5828923076923077,
      "grad_norm": 0.08447265625,
      "learning_rate": 2.41501976284585e-05,
      "loss": 0.0006,
      "step": 148
    },
    {
      "epoch": 0.5868307692307693,
      "grad_norm": 0.020263671875,
      "learning_rate": 2.4110671936758893e-05,
      "loss": 0.0004,
      "step": 149
    },
    {
      "epoch": 0.5907692307692308,
      "grad_norm": 0.310546875,
      "learning_rate": 2.407114624505929e-05,
      "loss": 0.0028,
      "step": 150
    },
    {
      "epoch": 0.5947076923076923,
      "grad_norm": 0.00958251953125,
      "learning_rate": 2.4031620553359682e-05,
      "loss": 0.0002,
      "step": 151
    },
    {
      "epoch": 0.5986461538461538,
      "grad_norm": 0.03466796875,
      "learning_rate": 2.399209486166008e-05,
      "loss": 0.0005,
      "step": 152
    },
    {
      "epoch": 0.6025846153846154,
      "grad_norm": 0.0302734375,
      "learning_rate": 2.3952569169960478e-05,
      "loss": 0.0005,
      "step": 153
    },
    {
      "epoch": 0.6065230769230769,
      "grad_norm": 0.05810546875,
      "learning_rate": 2.391304347826087e-05,
      "loss": 0.0009,
      "step": 154
    },
    {
      "epoch": 0.6104615384615385,
      "grad_norm": 0.0198974609375,
      "learning_rate": 2.3873517786561267e-05,
      "loss": 0.0003,
      "step": 155
    },
    {
      "epoch": 0.6144,
      "grad_norm": 0.052001953125,
      "learning_rate": 2.383399209486166e-05,
      "loss": 0.0007,
      "step": 156
    },
    {
      "epoch": 0.6183384615384615,
      "grad_norm": 0.08056640625,
      "learning_rate": 2.3794466403162056e-05,
      "loss": 0.0009,
      "step": 157
    },
    {
      "epoch": 0.6222769230769231,
      "grad_norm": 0.037109375,
      "learning_rate": 2.3754940711462452e-05,
      "loss": 0.0005,
      "step": 158
    },
    {
      "epoch": 0.6262153846153846,
      "grad_norm": 0.0255126953125,
      "learning_rate": 2.3715415019762845e-05,
      "loss": 0.0004,
      "step": 159
    },
    {
      "epoch": 0.6301538461538462,
      "grad_norm": 0.0203857421875,
      "learning_rate": 2.367588932806324e-05,
      "loss": 0.0003,
      "step": 160
    },
    {
      "epoch": 0.6340923076923077,
      "grad_norm": 0.027099609375,
      "learning_rate": 2.3636363636363637e-05,
      "loss": 0.0005,
      "step": 161
    },
    {
      "epoch": 0.6380307692307692,
      "grad_norm": 0.044189453125,
      "learning_rate": 2.3596837944664034e-05,
      "loss": 0.0005,
      "step": 162
    },
    {
      "epoch": 0.6419692307692307,
      "grad_norm": 0.01385498046875,
      "learning_rate": 2.3557312252964426e-05,
      "loss": 0.0002,
      "step": 163
    },
    {
      "epoch": 0.6459076923076923,
      "grad_norm": 0.027587890625,
      "learning_rate": 2.3517786561264823e-05,
      "loss": 0.0003,
      "step": 164
    },
    {
      "epoch": 0.6498461538461539,
      "grad_norm": 0.006866455078125,
      "learning_rate": 2.347826086956522e-05,
      "loss": 0.0001,
      "step": 165
    },
    {
      "epoch": 0.6537846153846154,
      "grad_norm": 0.02197265625,
      "learning_rate": 2.343873517786561e-05,
      "loss": 0.0004,
      "step": 166
    },
    {
      "epoch": 0.657723076923077,
      "grad_norm": 0.024169921875,
      "learning_rate": 2.3399209486166008e-05,
      "loss": 0.0004,
      "step": 167
    },
    {
      "epoch": 0.6616615384615384,
      "grad_norm": 0.057373046875,
      "learning_rate": 2.33596837944664e-05,
      "loss": 0.0007,
      "step": 168
    },
    {
      "epoch": 0.6656,
      "grad_norm": 0.00958251953125,
      "learning_rate": 2.33201581027668e-05,
      "loss": 0.0002,
      "step": 169
    },
    {
      "epoch": 0.6695384615384615,
      "grad_norm": 0.02099609375,
      "learning_rate": 2.3280632411067196e-05,
      "loss": 0.0002,
      "step": 170
    },
    {
      "epoch": 0.6734769230769231,
      "grad_norm": 0.0234375,
      "learning_rate": 2.324110671936759e-05,
      "loss": 0.0003,
      "step": 171
    },
    {
      "epoch": 0.6774153846153846,
      "grad_norm": 0.03515625,
      "learning_rate": 2.3201581027667985e-05,
      "loss": 0.0003,
      "step": 172
    },
    {
      "epoch": 0.6813538461538462,
      "grad_norm": 0.014404296875,
      "learning_rate": 2.3162055335968378e-05,
      "loss": 0.0002,
      "step": 173
    },
    {
      "epoch": 0.6852923076923076,
      "grad_norm": 0.039306640625,
      "learning_rate": 2.3122529644268774e-05,
      "loss": 0.0006,
      "step": 174
    },
    {
      "epoch": 0.6892307692307692,
      "grad_norm": 0.0198974609375,
      "learning_rate": 2.308300395256917e-05,
      "loss": 0.0003,
      "step": 175
    },
    {
      "epoch": 0.6931692307692308,
      "grad_norm": 0.00592041015625,
      "learning_rate": 2.3043478260869563e-05,
      "loss": 0.0001,
      "step": 176
    },
    {
      "epoch": 0.6971076923076923,
      "grad_norm": 0.039306640625,
      "learning_rate": 2.3003952569169963e-05,
      "loss": 0.0004,
      "step": 177
    },
    {
      "epoch": 0.7010461538461539,
      "grad_norm": 0.09765625,
      "learning_rate": 2.2964426877470356e-05,
      "loss": 0.0007,
      "step": 178
    },
    {
      "epoch": 0.7049846153846154,
      "grad_norm": 0.0068359375,
      "learning_rate": 2.2924901185770752e-05,
      "loss": 0.0002,
      "step": 179
    },
    {
      "epoch": 0.7089230769230769,
      "grad_norm": 0.045166015625,
      "learning_rate": 2.2885375494071148e-05,
      "loss": 0.0006,
      "step": 180
    },
    {
      "epoch": 0.7128615384615384,
      "grad_norm": 0.0101318359375,
      "learning_rate": 2.284584980237154e-05,
      "loss": 0.0002,
      "step": 181
    },
    {
      "epoch": 0.7168,
      "grad_norm": 0.69921875,
      "learning_rate": 2.2806324110671937e-05,
      "loss": 0.015,
      "step": 182
    },
    {
      "epoch": 0.7207384615384616,
      "grad_norm": 0.033203125,
      "learning_rate": 2.276679841897233e-05,
      "loss": 0.0004,
      "step": 183
    },
    {
      "epoch": 0.7246769230769231,
      "grad_norm": 0.125,
      "learning_rate": 2.272727272727273e-05,
      "loss": 0.0018,
      "step": 184
    },
    {
      "epoch": 0.7286153846153847,
      "grad_norm": 0.0120849609375,
      "learning_rate": 2.2687747035573125e-05,
      "loss": 0.0002,
      "step": 185
    },
    {
      "epoch": 0.7325538461538461,
      "grad_norm": 0.01055908203125,
      "learning_rate": 2.2648221343873518e-05,
      "loss": 0.0001,
      "step": 186
    },
    {
      "epoch": 0.7364923076923077,
      "grad_norm": 0.06982421875,
      "learning_rate": 2.2608695652173914e-05,
      "loss": 0.0008,
      "step": 187
    },
    {
      "epoch": 0.7404307692307692,
      "grad_norm": 0.04248046875,
      "learning_rate": 2.2569169960474307e-05,
      "loss": 0.0007,
      "step": 188
    },
    {
      "epoch": 0.7443692307692308,
      "grad_norm": 0.031982421875,
      "learning_rate": 2.2529644268774703e-05,
      "loss": 0.0004,
      "step": 189
    },
    {
      "epoch": 0.7483076923076923,
      "grad_norm": 0.1630859375,
      "learning_rate": 2.24901185770751e-05,
      "loss": 0.0009,
      "step": 190
    },
    {
      "epoch": 0.7522461538461539,
      "grad_norm": 0.02392578125,
      "learning_rate": 2.2450592885375492e-05,
      "loss": 0.0003,
      "step": 191
    },
    {
      "epoch": 0.7561846153846153,
      "grad_norm": 0.0262451171875,
      "learning_rate": 2.2411067193675892e-05,
      "loss": 0.0004,
      "step": 192
    },
    {
      "epoch": 0.7601230769230769,
      "grad_norm": 0.03662109375,
      "learning_rate": 2.2371541501976285e-05,
      "loss": 0.0007,
      "step": 193
    },
    {
      "epoch": 0.7640615384615385,
      "grad_norm": 0.048828125,
      "learning_rate": 2.233201581027668e-05,
      "loss": 0.0006,
      "step": 194
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.01953125,
      "learning_rate": 2.2292490118577077e-05,
      "loss": 0.0003,
      "step": 195
    },
    {
      "epoch": 0.7719384615384616,
      "grad_norm": 0.0751953125,
      "learning_rate": 2.225296442687747e-05,
      "loss": 0.0004,
      "step": 196
    },
    {
      "epoch": 0.7758769230769231,
      "grad_norm": 0.01239013671875,
      "learning_rate": 2.2213438735177866e-05,
      "loss": 0.0002,
      "step": 197
    },
    {
      "epoch": 0.7798153846153846,
      "grad_norm": 0.076171875,
      "learning_rate": 2.217391304347826e-05,
      "loss": 0.0008,
      "step": 198
    },
    {
      "epoch": 0.7837538461538461,
      "grad_norm": 0.01806640625,
      "learning_rate": 2.2134387351778655e-05,
      "loss": 0.0002,
      "step": 199
    },
    {
      "epoch": 0.7876923076923077,
      "grad_norm": 0.019287109375,
      "learning_rate": 2.2094861660079055e-05,
      "loss": 0.0003,
      "step": 200
    }
  ],
  "logging_steps": 1,
  "max_steps": 759,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
