{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.022831661092530656,
  "eval_steps": 500,
  "global_step": 40,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0005707915273132665,
      "grad_norm": 4.3125,
      "learning_rate": 2.9994288977727013e-05,
      "loss": 0.5774,
      "step": 1
    },
    {
      "epoch": 0.001141583054626533,
      "grad_norm": 1.03125,
      "learning_rate": 2.998857795545403e-05,
      "loss": 0.6062,
      "step": 2
    },
    {
      "epoch": 0.0017123745819397993,
      "grad_norm": 1.15625,
      "learning_rate": 2.998286693318104e-05,
      "loss": 0.5913,
      "step": 3
    },
    {
      "epoch": 0.002283166109253066,
      "grad_norm": 1.25,
      "learning_rate": 2.9977155910908053e-05,
      "loss": 0.51,
      "step": 4
    },
    {
      "epoch": 0.002853957636566332,
      "grad_norm": 1.2890625,
      "learning_rate": 2.9971444888635065e-05,
      "loss": 0.4734,
      "step": 5
    },
    {
      "epoch": 0.0034247491638795986,
      "grad_norm": 1.3125,
      "learning_rate": 2.996573386636208e-05,
      "loss": 0.4566,
      "step": 6
    },
    {
      "epoch": 0.003995540691192865,
      "grad_norm": 1.265625,
      "learning_rate": 2.9960022844089092e-05,
      "loss": 0.3998,
      "step": 7
    },
    {
      "epoch": 0.004566332218506132,
      "grad_norm": 1.34375,
      "learning_rate": 2.9954311821816108e-05,
      "loss": 0.3361,
      "step": 8
    },
    {
      "epoch": 0.005137123745819398,
      "grad_norm": 1.2890625,
      "learning_rate": 2.994860079954312e-05,
      "loss": 0.2833,
      "step": 9
    },
    {
      "epoch": 0.005707915273132664,
      "grad_norm": 1.390625,
      "learning_rate": 2.9942889777270132e-05,
      "loss": 0.2787,
      "step": 10
    },
    {
      "epoch": 0.006278706800445931,
      "grad_norm": 1.2578125,
      "learning_rate": 2.9937178754997144e-05,
      "loss": 0.2515,
      "step": 11
    },
    {
      "epoch": 0.006849498327759197,
      "grad_norm": 1.5,
      "learning_rate": 2.9931467732724156e-05,
      "loss": 0.2385,
      "step": 12
    },
    {
      "epoch": 0.007420289855072463,
      "grad_norm": 2.0,
      "learning_rate": 2.9925756710451172e-05,
      "loss": 0.2067,
      "step": 13
    },
    {
      "epoch": 0.00799108138238573,
      "grad_norm": 2.1875,
      "learning_rate": 2.9920045688178184e-05,
      "loss": 0.2204,
      "step": 14
    },
    {
      "epoch": 0.008561872909698997,
      "grad_norm": 1.203125,
      "learning_rate": 2.99143346659052e-05,
      "loss": 0.1557,
      "step": 15
    },
    {
      "epoch": 0.009132664437012264,
      "grad_norm": 1.1953125,
      "learning_rate": 2.990862364363221e-05,
      "loss": 0.1763,
      "step": 16
    },
    {
      "epoch": 0.009703455964325529,
      "grad_norm": 0.9921875,
      "learning_rate": 2.9902912621359224e-05,
      "loss": 0.1211,
      "step": 17
    },
    {
      "epoch": 0.010274247491638796,
      "grad_norm": 0.8828125,
      "learning_rate": 2.9897201599086236e-05,
      "loss": 0.1077,
      "step": 18
    },
    {
      "epoch": 0.010845039018952063,
      "grad_norm": 0.83984375,
      "learning_rate": 2.989149057681325e-05,
      "loss": 0.1172,
      "step": 19
    },
    {
      "epoch": 0.011415830546265328,
      "grad_norm": 0.75,
      "learning_rate": 2.9885779554540263e-05,
      "loss": 0.1087,
      "step": 20
    },
    {
      "epoch": 0.011986622073578595,
      "grad_norm": 0.75390625,
      "learning_rate": 2.9880068532267276e-05,
      "loss": 0.0914,
      "step": 21
    },
    {
      "epoch": 0.012557413600891862,
      "grad_norm": 0.578125,
      "learning_rate": 2.987435750999429e-05,
      "loss": 0.0737,
      "step": 22
    },
    {
      "epoch": 0.013128205128205127,
      "grad_norm": 0.91796875,
      "learning_rate": 2.9868646487721303e-05,
      "loss": 0.0747,
      "step": 23
    },
    {
      "epoch": 0.013698996655518395,
      "grad_norm": 0.71875,
      "learning_rate": 2.9862935465448315e-05,
      "loss": 0.0776,
      "step": 24
    },
    {
      "epoch": 0.014269788182831662,
      "grad_norm": 0.609375,
      "learning_rate": 2.9857224443175327e-05,
      "loss": 0.058,
      "step": 25
    },
    {
      "epoch": 0.014840579710144927,
      "grad_norm": 0.58984375,
      "learning_rate": 2.9851513420902343e-05,
      "loss": 0.0568,
      "step": 26
    },
    {
      "epoch": 0.015411371237458194,
      "grad_norm": 0.7109375,
      "learning_rate": 2.9845802398629355e-05,
      "loss": 0.0753,
      "step": 27
    },
    {
      "epoch": 0.01598216276477146,
      "grad_norm": 0.56640625,
      "learning_rate": 2.984009137635637e-05,
      "loss": 0.0467,
      "step": 28
    },
    {
      "epoch": 0.016552954292084726,
      "grad_norm": 0.49609375,
      "learning_rate": 2.9834380354083383e-05,
      "loss": 0.0459,
      "step": 29
    },
    {
      "epoch": 0.017123745819397993,
      "grad_norm": 0.45703125,
      "learning_rate": 2.9828669331810398e-05,
      "loss": 0.0587,
      "step": 30
    },
    {
      "epoch": 0.01769453734671126,
      "grad_norm": 0.41796875,
      "learning_rate": 2.9822958309537407e-05,
      "loss": 0.0408,
      "step": 31
    },
    {
      "epoch": 0.018265328874024527,
      "grad_norm": 0.4921875,
      "learning_rate": 2.981724728726442e-05,
      "loss": 0.0463,
      "step": 32
    },
    {
      "epoch": 0.018836120401337794,
      "grad_norm": 0.5625,
      "learning_rate": 2.9811536264991434e-05,
      "loss": 0.0345,
      "step": 33
    },
    {
      "epoch": 0.019406911928651058,
      "grad_norm": 0.482421875,
      "learning_rate": 2.9805825242718447e-05,
      "loss": 0.0616,
      "step": 34
    },
    {
      "epoch": 0.019977703455964325,
      "grad_norm": 0.33203125,
      "learning_rate": 2.9800114220445462e-05,
      "loss": 0.0383,
      "step": 35
    },
    {
      "epoch": 0.020548494983277592,
      "grad_norm": 0.34375,
      "learning_rate": 2.9794403198172474e-05,
      "loss": 0.0347,
      "step": 36
    },
    {
      "epoch": 0.02111928651059086,
      "grad_norm": 0.416015625,
      "learning_rate": 2.9788692175899486e-05,
      "loss": 0.0381,
      "step": 37
    },
    {
      "epoch": 0.021690078037904126,
      "grad_norm": 0.30078125,
      "learning_rate": 2.97829811536265e-05,
      "loss": 0.0377,
      "step": 38
    },
    {
      "epoch": 0.022260869565217393,
      "grad_norm": 0.439453125,
      "learning_rate": 2.9777270131353514e-05,
      "loss": 0.0423,
      "step": 39
    },
    {
      "epoch": 0.022831661092530656,
      "grad_norm": 0.328125,
      "learning_rate": 2.9771559109080526e-05,
      "loss": 0.0498,
      "step": 40
    }
  ],
  "logging_steps": 1,
  "max_steps": 5253,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
