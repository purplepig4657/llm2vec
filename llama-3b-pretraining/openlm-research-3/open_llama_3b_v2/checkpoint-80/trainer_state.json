{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.04566332218506131,
  "eval_steps": 500,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0005707915273132665,
      "grad_norm": 4.3125,
      "learning_rate": 2.9994288977727013e-05,
      "loss": 0.5774,
      "step": 1
    },
    {
      "epoch": 0.001141583054626533,
      "grad_norm": 1.03125,
      "learning_rate": 2.998857795545403e-05,
      "loss": 0.6062,
      "step": 2
    },
    {
      "epoch": 0.0017123745819397993,
      "grad_norm": 1.15625,
      "learning_rate": 2.998286693318104e-05,
      "loss": 0.5913,
      "step": 3
    },
    {
      "epoch": 0.002283166109253066,
      "grad_norm": 1.25,
      "learning_rate": 2.9977155910908053e-05,
      "loss": 0.51,
      "step": 4
    },
    {
      "epoch": 0.002853957636566332,
      "grad_norm": 1.2890625,
      "learning_rate": 2.9971444888635065e-05,
      "loss": 0.4734,
      "step": 5
    },
    {
      "epoch": 0.0034247491638795986,
      "grad_norm": 1.3125,
      "learning_rate": 2.996573386636208e-05,
      "loss": 0.4566,
      "step": 6
    },
    {
      "epoch": 0.003995540691192865,
      "grad_norm": 1.265625,
      "learning_rate": 2.9960022844089092e-05,
      "loss": 0.3998,
      "step": 7
    },
    {
      "epoch": 0.004566332218506132,
      "grad_norm": 1.34375,
      "learning_rate": 2.9954311821816108e-05,
      "loss": 0.3361,
      "step": 8
    },
    {
      "epoch": 0.005137123745819398,
      "grad_norm": 1.2890625,
      "learning_rate": 2.994860079954312e-05,
      "loss": 0.2833,
      "step": 9
    },
    {
      "epoch": 0.005707915273132664,
      "grad_norm": 1.390625,
      "learning_rate": 2.9942889777270132e-05,
      "loss": 0.2787,
      "step": 10
    },
    {
      "epoch": 0.006278706800445931,
      "grad_norm": 1.2578125,
      "learning_rate": 2.9937178754997144e-05,
      "loss": 0.2515,
      "step": 11
    },
    {
      "epoch": 0.006849498327759197,
      "grad_norm": 1.5,
      "learning_rate": 2.9931467732724156e-05,
      "loss": 0.2385,
      "step": 12
    },
    {
      "epoch": 0.007420289855072463,
      "grad_norm": 2.0,
      "learning_rate": 2.9925756710451172e-05,
      "loss": 0.2067,
      "step": 13
    },
    {
      "epoch": 0.00799108138238573,
      "grad_norm": 2.1875,
      "learning_rate": 2.9920045688178184e-05,
      "loss": 0.2204,
      "step": 14
    },
    {
      "epoch": 0.008561872909698997,
      "grad_norm": 1.203125,
      "learning_rate": 2.99143346659052e-05,
      "loss": 0.1557,
      "step": 15
    },
    {
      "epoch": 0.009132664437012264,
      "grad_norm": 1.1953125,
      "learning_rate": 2.990862364363221e-05,
      "loss": 0.1763,
      "step": 16
    },
    {
      "epoch": 0.009703455964325529,
      "grad_norm": 0.9921875,
      "learning_rate": 2.9902912621359224e-05,
      "loss": 0.1211,
      "step": 17
    },
    {
      "epoch": 0.010274247491638796,
      "grad_norm": 0.8828125,
      "learning_rate": 2.9897201599086236e-05,
      "loss": 0.1077,
      "step": 18
    },
    {
      "epoch": 0.010845039018952063,
      "grad_norm": 0.83984375,
      "learning_rate": 2.989149057681325e-05,
      "loss": 0.1172,
      "step": 19
    },
    {
      "epoch": 0.011415830546265328,
      "grad_norm": 0.75,
      "learning_rate": 2.9885779554540263e-05,
      "loss": 0.1087,
      "step": 20
    },
    {
      "epoch": 0.011986622073578595,
      "grad_norm": 0.75390625,
      "learning_rate": 2.9880068532267276e-05,
      "loss": 0.0914,
      "step": 21
    },
    {
      "epoch": 0.012557413600891862,
      "grad_norm": 0.578125,
      "learning_rate": 2.987435750999429e-05,
      "loss": 0.0737,
      "step": 22
    },
    {
      "epoch": 0.013128205128205127,
      "grad_norm": 0.91796875,
      "learning_rate": 2.9868646487721303e-05,
      "loss": 0.0747,
      "step": 23
    },
    {
      "epoch": 0.013698996655518395,
      "grad_norm": 0.71875,
      "learning_rate": 2.9862935465448315e-05,
      "loss": 0.0776,
      "step": 24
    },
    {
      "epoch": 0.014269788182831662,
      "grad_norm": 0.609375,
      "learning_rate": 2.9857224443175327e-05,
      "loss": 0.058,
      "step": 25
    },
    {
      "epoch": 0.014840579710144927,
      "grad_norm": 0.58984375,
      "learning_rate": 2.9851513420902343e-05,
      "loss": 0.0568,
      "step": 26
    },
    {
      "epoch": 0.015411371237458194,
      "grad_norm": 0.7109375,
      "learning_rate": 2.9845802398629355e-05,
      "loss": 0.0753,
      "step": 27
    },
    {
      "epoch": 0.01598216276477146,
      "grad_norm": 0.56640625,
      "learning_rate": 2.984009137635637e-05,
      "loss": 0.0467,
      "step": 28
    },
    {
      "epoch": 0.016552954292084726,
      "grad_norm": 0.49609375,
      "learning_rate": 2.9834380354083383e-05,
      "loss": 0.0459,
      "step": 29
    },
    {
      "epoch": 0.017123745819397993,
      "grad_norm": 0.45703125,
      "learning_rate": 2.9828669331810398e-05,
      "loss": 0.0587,
      "step": 30
    },
    {
      "epoch": 0.01769453734671126,
      "grad_norm": 0.41796875,
      "learning_rate": 2.9822958309537407e-05,
      "loss": 0.0408,
      "step": 31
    },
    {
      "epoch": 0.018265328874024527,
      "grad_norm": 0.4921875,
      "learning_rate": 2.981724728726442e-05,
      "loss": 0.0463,
      "step": 32
    },
    {
      "epoch": 0.018836120401337794,
      "grad_norm": 0.5625,
      "learning_rate": 2.9811536264991434e-05,
      "loss": 0.0345,
      "step": 33
    },
    {
      "epoch": 0.019406911928651058,
      "grad_norm": 0.482421875,
      "learning_rate": 2.9805825242718447e-05,
      "loss": 0.0616,
      "step": 34
    },
    {
      "epoch": 0.019977703455964325,
      "grad_norm": 0.33203125,
      "learning_rate": 2.9800114220445462e-05,
      "loss": 0.0383,
      "step": 35
    },
    {
      "epoch": 0.020548494983277592,
      "grad_norm": 0.34375,
      "learning_rate": 2.9794403198172474e-05,
      "loss": 0.0347,
      "step": 36
    },
    {
      "epoch": 0.02111928651059086,
      "grad_norm": 0.416015625,
      "learning_rate": 2.9788692175899486e-05,
      "loss": 0.0381,
      "step": 37
    },
    {
      "epoch": 0.021690078037904126,
      "grad_norm": 0.30078125,
      "learning_rate": 2.97829811536265e-05,
      "loss": 0.0377,
      "step": 38
    },
    {
      "epoch": 0.022260869565217393,
      "grad_norm": 0.439453125,
      "learning_rate": 2.9777270131353514e-05,
      "loss": 0.0423,
      "step": 39
    },
    {
      "epoch": 0.022831661092530656,
      "grad_norm": 0.328125,
      "learning_rate": 2.9771559109080526e-05,
      "loss": 0.0498,
      "step": 40
    },
    {
      "epoch": 0.023402452619843923,
      "grad_norm": 0.322265625,
      "learning_rate": 2.9765848086807538e-05,
      "loss": 0.0327,
      "step": 41
    },
    {
      "epoch": 0.02397324414715719,
      "grad_norm": 0.35546875,
      "learning_rate": 2.9760137064534554e-05,
      "loss": 0.0562,
      "step": 42
    },
    {
      "epoch": 0.024544035674470457,
      "grad_norm": 0.37109375,
      "learning_rate": 2.9754426042261566e-05,
      "loss": 0.0381,
      "step": 43
    },
    {
      "epoch": 0.025114827201783724,
      "grad_norm": 0.70703125,
      "learning_rate": 2.9748715019988578e-05,
      "loss": 0.0566,
      "step": 44
    },
    {
      "epoch": 0.02568561872909699,
      "grad_norm": 0.515625,
      "learning_rate": 2.974300399771559e-05,
      "loss": 0.0481,
      "step": 45
    },
    {
      "epoch": 0.026256410256410255,
      "grad_norm": 0.412109375,
      "learning_rate": 2.9737292975442606e-05,
      "loss": 0.0498,
      "step": 46
    },
    {
      "epoch": 0.026827201783723522,
      "grad_norm": 0.5234375,
      "learning_rate": 2.9731581953169618e-05,
      "loss": 0.0403,
      "step": 47
    },
    {
      "epoch": 0.02739799331103679,
      "grad_norm": 0.349609375,
      "learning_rate": 2.9725870930896633e-05,
      "loss": 0.0504,
      "step": 48
    },
    {
      "epoch": 0.027968784838350056,
      "grad_norm": 1.078125,
      "learning_rate": 2.9720159908623645e-05,
      "loss": 0.0453,
      "step": 49
    },
    {
      "epoch": 0.028539576365663323,
      "grad_norm": 0.3671875,
      "learning_rate": 2.971444888635066e-05,
      "loss": 0.0454,
      "step": 50
    },
    {
      "epoch": 0.02911036789297659,
      "grad_norm": 0.345703125,
      "learning_rate": 2.970873786407767e-05,
      "loss": 0.0393,
      "step": 51
    },
    {
      "epoch": 0.029681159420289854,
      "grad_norm": 0.3046875,
      "learning_rate": 2.970302684180468e-05,
      "loss": 0.0349,
      "step": 52
    },
    {
      "epoch": 0.03025195094760312,
      "grad_norm": 0.400390625,
      "learning_rate": 2.9697315819531697e-05,
      "loss": 0.0356,
      "step": 53
    },
    {
      "epoch": 0.030822742474916388,
      "grad_norm": 0.32421875,
      "learning_rate": 2.969160479725871e-05,
      "loss": 0.0341,
      "step": 54
    },
    {
      "epoch": 0.031393534002229655,
      "grad_norm": 0.216796875,
      "learning_rate": 2.9685893774985725e-05,
      "loss": 0.0222,
      "step": 55
    },
    {
      "epoch": 0.03196432552954292,
      "grad_norm": 0.298828125,
      "learning_rate": 2.9680182752712737e-05,
      "loss": 0.0353,
      "step": 56
    },
    {
      "epoch": 0.03253511705685619,
      "grad_norm": 0.24609375,
      "learning_rate": 2.967447173043975e-05,
      "loss": 0.0277,
      "step": 57
    },
    {
      "epoch": 0.03310590858416945,
      "grad_norm": 0.353515625,
      "learning_rate": 2.966876070816676e-05,
      "loss": 0.0358,
      "step": 58
    },
    {
      "epoch": 0.03367670011148272,
      "grad_norm": 0.33203125,
      "learning_rate": 2.9663049685893777e-05,
      "loss": 0.0316,
      "step": 59
    },
    {
      "epoch": 0.034247491638795986,
      "grad_norm": 0.345703125,
      "learning_rate": 2.965733866362079e-05,
      "loss": 0.0285,
      "step": 60
    },
    {
      "epoch": 0.03481828316610925,
      "grad_norm": 0.439453125,
      "learning_rate": 2.96516276413478e-05,
      "loss": 0.0301,
      "step": 61
    },
    {
      "epoch": 0.03538907469342252,
      "grad_norm": 0.26171875,
      "learning_rate": 2.9645916619074816e-05,
      "loss": 0.0282,
      "step": 62
    },
    {
      "epoch": 0.035959866220735784,
      "grad_norm": 0.330078125,
      "learning_rate": 2.964020559680183e-05,
      "loss": 0.0413,
      "step": 63
    },
    {
      "epoch": 0.036530657748049054,
      "grad_norm": 0.5390625,
      "learning_rate": 2.963449457452884e-05,
      "loss": 0.0398,
      "step": 64
    },
    {
      "epoch": 0.03710144927536232,
      "grad_norm": 0.30859375,
      "learning_rate": 2.9628783552255853e-05,
      "loss": 0.0343,
      "step": 65
    },
    {
      "epoch": 0.03767224080267559,
      "grad_norm": 0.376953125,
      "learning_rate": 2.9623072529982868e-05,
      "loss": 0.0354,
      "step": 66
    },
    {
      "epoch": 0.03824303232998885,
      "grad_norm": 0.341796875,
      "learning_rate": 2.961736150770988e-05,
      "loss": 0.0536,
      "step": 67
    },
    {
      "epoch": 0.038813823857302115,
      "grad_norm": 0.35546875,
      "learning_rate": 2.9611650485436896e-05,
      "loss": 0.0234,
      "step": 68
    },
    {
      "epoch": 0.039384615384615386,
      "grad_norm": 0.259765625,
      "learning_rate": 2.9605939463163908e-05,
      "loss": 0.0421,
      "step": 69
    },
    {
      "epoch": 0.03995540691192865,
      "grad_norm": 0.30859375,
      "learning_rate": 2.9600228440890923e-05,
      "loss": 0.0265,
      "step": 70
    },
    {
      "epoch": 0.04052619843924192,
      "grad_norm": 0.251953125,
      "learning_rate": 2.9594517418617932e-05,
      "loss": 0.0274,
      "step": 71
    },
    {
      "epoch": 0.041096989966555184,
      "grad_norm": 0.298828125,
      "learning_rate": 2.9588806396344944e-05,
      "loss": 0.0349,
      "step": 72
    },
    {
      "epoch": 0.04166778149386845,
      "grad_norm": 0.53125,
      "learning_rate": 2.958309537407196e-05,
      "loss": 0.0383,
      "step": 73
    },
    {
      "epoch": 0.04223857302118172,
      "grad_norm": 0.310546875,
      "learning_rate": 2.9577384351798972e-05,
      "loss": 0.0303,
      "step": 74
    },
    {
      "epoch": 0.04280936454849498,
      "grad_norm": 0.302734375,
      "learning_rate": 2.9571673329525987e-05,
      "loss": 0.0244,
      "step": 75
    },
    {
      "epoch": 0.04338015607580825,
      "grad_norm": 0.76171875,
      "learning_rate": 2.9565962307253e-05,
      "loss": 0.0216,
      "step": 76
    },
    {
      "epoch": 0.043950947603121515,
      "grad_norm": 0.36328125,
      "learning_rate": 2.956025128498001e-05,
      "loss": 0.0323,
      "step": 77
    },
    {
      "epoch": 0.044521739130434786,
      "grad_norm": 0.546875,
      "learning_rate": 2.9554540262707024e-05,
      "loss": 0.0385,
      "step": 78
    },
    {
      "epoch": 0.04509253065774805,
      "grad_norm": 0.380859375,
      "learning_rate": 2.954882924043404e-05,
      "loss": 0.0337,
      "step": 79
    },
    {
      "epoch": 0.04566332218506131,
      "grad_norm": 0.318359375,
      "learning_rate": 2.954311821816105e-05,
      "loss": 0.0239,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 5253,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
